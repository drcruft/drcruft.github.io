```python
import streamlit as st
import os
import openai
from typing import List, Dict

# Initialize the page configuration for a professional look
def init_page():
    st.set_page_config(
        page_title="LLM Chat UI",
        page_icon="💬",
        layout="wide",
        initial_sidebar_state="collapsed"
    )
    # Custom CSS for avatar background colors
    st.markdown(
        """
        <style>
        /* User avatar color */
        .stChatMessage[data-testid='stChatMessage-user'] .stChatMessageAvatar {
            background-color: #4F46E5 !important; /* Indigo */
        }
        /* Assistant avatar color */
        .stChatMessage[data-testid='stChatMessage-assistant'] .stChatMessageAvatar {
            background-color: #059669 !important; /* Emerald */
        }
        </style>
        """,
        unsafe_allow_html=True
    )

# Render chat history stored in Session State with custom icons
def render_chat(messages: List[Dict[str, str]]):
    # Define custom avatars (could be emojis or image URLs)
    avatar_map = {
        "user": "🧑‍💻",
        "assistant": "🤖"
    }
    with st.container():
        for msg in messages:
            role = msg.get("role")
            content = msg.get("content", "")
            avatar = avatar_map.get(role)
            # Use built-in chat message with custom avatar
            st.chat_message(role, avatar=avatar).markdown(content)

# Main application
def main():
    init_page()

    # Configure OpenAI-compatible API for Command-R via VLLM
    openai.api_key = os.getenv("OPENAI_API_KEY")
    openai.api_base = os.getenv("COMMANDR_API_BASE", "http://localhost:8080/v1")

    # Initialize session state for chat history
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Display existing chat history (oldest at top)
    render_chat(st.session_state.messages)

    # Chat input at the bottom
    user_input = st.chat_input("Type your message here...")
    if user_input:
        # Append user's message
        st.session_state.messages.append({"role": "user", "content": user_input})
        st.chat_message("user", avatar=avatar_map.get("user")).markdown(user_input)

        # Only send the last 10 messages for context
        context = st.session_state.messages[-10:]

        # Call the LLM with truncated conversation context
        response = openai.ChatCompletion.create(
            model="command-r",
            messages=context,
            temperature=0.7,
            max_tokens=512,
        )
        llm_response = response.choices[0].message.content

        # Append assistant's response to history and render with custom avatar
        st.session_state.messages.append({"role": "assistant", "content": llm_response})
        st.chat_message("assistant", avatar=avatar_map.get("assistant")).markdown(llm_response)

if __name__ == "__main__":
    main()

```