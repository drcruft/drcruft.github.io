Here’s a drop-in Jinja2 chat template you can use with vLLM to serve the Cohere Command-R model (e.g. `CohereLabs/c4ai-command-r-v01`). It implements the exact turn-taking tokens that Command-R was trained with, and will mark where the model should begin generating its reply:

```jinja
{{ bos_token }}
{% for message in messages %}
  {#-- Each turn must begin with START_OF_TURN, then the appropriate role token, then content, then END_OF_TURN --#}
  {% if message.role == "system" %}
    {{ start_of_turn_token }}{{ system_token }}{{ message.content }}{{ end_of_turn_token }}
  {% elif message.role == "user" %}
    {{ start_of_turn_token }}{{ user_token }}{{ message.content }}{{ end_of_turn_token }}
  {% elif message.role == "assistant" %}
    {{ start_of_turn_token }}{{ chatbot_token }}{{ message.content }}{{ end_of_turn_token }}
  {% else %}
    {{ raise_exception("Unsupported role: " ~ message.role) }}
  {% endif %}
{% endfor %}
{#-- Now tell the model to start its next assistant turn --#}
{{ start_of_turn_token }}{{ chatbot_token }}
```

#### How it works

* **`bos_token`**: Inserts the model’s beginning-of-sequence token, as required by Command-R ([docs.cohere.com][1]).
* **`start_of_turn_token`**, **`end_of_turn_token`**, **`user_token`**, **`system_token`**, **`chatbot_token`**: Wrap every user, system, and assistant message exactly in the special tokens Command-R expects (e.g. `<|START_OF_TURN_TOKEN|><|USER_TOKEN|>…<|END_OF_TURN_TOKEN|>`) ([docs.cohere.com][1], [docs.cohere.com][1]).
* The final line (`{{ start_of_turn_token }}{{ chatbot_token }}`) cues the model to generate the assistant’s next response.

#### Usage

Save this as, say, `command_r_chat_template.jinja`, then launch vLLM like:

```bash
vllm serve CohereLabs/c4ai-command-r-v01 \
  --chat-template ./command_r_chat_template.jinja \
  --api-key YOUR_KEY
```

Your HTTP client can now call the standard OpenAI-compatible chat endpoint:

```json
POST /v1/chat/completions
{
  "model": "CohereLabs/c4ai-command-r-v01",
  "messages": [
    {"role":"system","content":"You are a helpful assistant."},
    {"role":"user","content":"Explain how GPS spoofing works."}
  ]
}
```

and vLLM will format the input using the template above, ensuring optimal performance with Command-R’s training regimen.

[1]: https://docs.cohere.com/docs/prompting-command-r "Prompting Command R and R+ | Cohere"

